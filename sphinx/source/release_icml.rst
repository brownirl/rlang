RLang Published at ICML 2023!
=============================

We're thrilled to announce the release of RLang, an innovative domain-specific language (DSL) designed to facilitate communication of domain knowledge to reinforcement learning (RL) agents, presented at the ICML 2023.

Unlike traditional RL DSLs that ground to individual elements of decision-making formalism, such as the reward function or policy, RLang stands out by allowing specification of information about every element of a Markov decision process. This unique capability allows RL agents to exploit a wide array of domain knowledge, which accelerates learning.

RLang comes with precise syntax and grounding semantics, accompanied by a parser that grounds RLang programs to an algorithm-agnostic partial world model and policy. This grounding can be leveraged by RL agents across a broad range of methods and algorithms, from model-free and model-based tabular algorithms to policy gradient and value-based methods, hierarchical approaches, and deep methods.

This library provides a selection of example RLang programs, showcasing the versatility of the language across different RL methods and demonstrating its potential to enhance the exploitation of knowledge in RL applications.

We believe that RLang will be a powerful tool for researchers, data scientists, and anyone involved in reinforcement learning projects, enabling them to express domain knowledge more effectively and enhance the learning capabilities of RL agents. We're excited to see the innovative applications and research that will be empowered by this new tool.

Stay tuned for future updates as we continue to enhance and expand the capabilities of RLang!

-Benjamin Spiegel